"""
å†œä¸šç—…è™«å®³ç›‘æµ‹ YOLO æ¨¡å‹è®­ç»ƒ
ä¼˜åŒ–å¢å¼ºç‰ˆ - æå‡å‡†ç¡®ç‡ + å®Œæ•´ä¿å­˜åŠŸèƒ½
"""

import os
import shutil
import random
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from ultralytics import YOLO
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from collections import Counter
from tqdm import tqdm
import cv2

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def prepare_classification_dataset(source_dir, output_dir, train_ratio=0.8):
    """å‡†å¤‡åˆ†ç±»æ•°æ®é›†"""
    source_dir = Path(source_dir)
    output_dir = Path(output_dir)
    
    if output_dir.exists():
        shutil.rmtree(output_dir)
    
    img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    
    class_names = sorted([
        d.name for d in source_dir.iterdir() 
        if d.is_dir() and not d.name.startswith('.')
    ])
    
    print(f"å‘ç° {len(class_names)} ä¸ªç±»åˆ«: {class_names}")
    
    stats = {}
    
    for class_name in class_names:
        class_dir = source_dir / class_name
        images = [f for f in class_dir.iterdir() if f.suffix.lower() in img_extensions]
        stats[class_name] = len(images)
        
        print(f"  {class_name}: {len(images)} å¼ å›¾åƒ")
        
        if len(images) < 2:
            train_imgs, val_imgs = images, []
        else:
            train_imgs, val_imgs = train_test_split(
                images, test_size=1-train_ratio, random_state=42
            )
        
        train_dir = output_dir / 'train' / class_name
        val_dir = output_dir / 'val' / class_name
        train_dir.mkdir(parents=True, exist_ok=True)
        val_dir.mkdir(parents=True, exist_ok=True)
        
        for img in train_imgs:
            shutil.copy2(img, train_dir / img.name)
        for img in val_imgs:
            shutil.copy2(img, val_dir / img.name)
    
    print(f"\næ•°æ®é›†å‡†å¤‡å®Œæˆ!")
    return class_names, stats


def visualize_dataset(source_dir, stats, save_path='dataset_distribution.png'):
    """å¯è§†åŒ–æ•°æ®é›†åˆ†å¸ƒ"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    classes = list(stats.keys())
    counts = list(stats.values())
    colors = plt.cm.viridis(np.linspace(0, 1, len(classes)))
    
    ax1 = axes[0]
    bars = ax1.barh(classes, counts, color=colors)
    ax1.set_xlabel('å›¾åƒæ•°é‡')
    ax1.set_title('å„ç±»åˆ«å›¾åƒæ•°é‡')
    ax1.bar_label(bars, padding=3)
    
    ax2 = axes[1]
    ax2.pie(counts, labels=classes, autopct='%1.1f%%', colors=colors)
    ax2.set_title('å„ç±»åˆ«å æ¯”')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def show_sample_images(source_dir, num_per_class=3, save_path='sample_images.png'):
    """å±•ç¤ºæ ·æœ¬å›¾åƒ"""
    source_dir = Path(source_dir)
    img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    
    class_dirs = sorted([d for d in source_dir.iterdir() 
                         if d.is_dir() and not d.name.startswith('.')])
    num_classes = len(class_dirs)
    
    fig, axes = plt.subplots(num_classes, num_per_class, 
                             figsize=(num_per_class * 3, num_classes * 2.5))
    
    if num_classes == 1:
        axes = axes.reshape(1, -1)
    
    for i, class_dir in enumerate(class_dirs):
        images = [f for f in class_dir.iterdir() if f.suffix.lower() in img_extensions]
        samples = random.sample(images, min(num_per_class, len(images)))
        
        for j in range(num_per_class):
            ax = axes[i, j] if num_classes > 1 else axes[j]
            if j < len(samples):
                img = plt.imread(str(samples[j]))
                ax.imshow(img)
                if j == 0:
                    ax.set_ylabel(class_dir.name, fontsize=10)
            ax.axis('off')
    
    plt.suptitle('å„ç±»åˆ«æ ·æœ¬å›¾åƒ', fontsize=14)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def train_model_optimized(data_dir, epochs=100, imgsz=320, batch=32, model_size='s'):
    """
    ä¼˜åŒ–ç‰ˆè®­ç»ƒå‡½æ•° - æå‡å‡†ç¡®ç‡
    """
    model_name = f'yolov8{model_size}-cls.pt'
    print(f"\nåŠ è½½æ¨¡å‹: {model_name}")
    print("=" * 50)
    print("ä¼˜åŒ–å‚æ•°é…ç½®:")
    print(f"  - è®­ç»ƒè½®æ•°: {epochs}")
    print(f"  - å›¾åƒå°ºå¯¸: {imgsz}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {batch}")
    print(f"  - æ¨¡å‹å¤§å°: {model_size}")
    print(f"  - æ•°æ®å¢å¼º: å·²å¯ç”¨")
    print(f"  - æ ‡ç­¾å¹³æ»‘: 0.1")
    print(f"  - ä½™å¼¦å­¦ä¹ ç‡: å·²å¯ç”¨")
    print("=" * 50)
    
    model = YOLO(model_name)
    
    results = model.train(
        data=str(data_dir),
        epochs=epochs,
        imgsz=imgsz,
        batch=batch,
        project='runs/classify',
        name='pest_disease_optimized',
        
        # å­¦ä¹ ç‡è®¾ç½®
        lr0=0.001,
        lrf=0.01,
        warmup_epochs=5,
        warmup_momentum=0.8,
        
        # ä¼˜åŒ–å™¨
        optimizer='AdamW',
        weight_decay=0.0005,
        momentum=0.937,
        
        # æ•°æ®å¢å¼º
        hsv_h=0.015,
        hsv_s=0.7,
        hsv_v=0.4,
        degrees=15.0,
        translate=0.1,
        scale=0.5,
        shear=2.0,
        perspective=0.0001,
        flipud=0.1,
        fliplr=0.5,
        mosaic=0.5,
        mixup=0.1,
        erasing=0.2,
        
        # è®­ç»ƒç­–ç•¥
        patience=30,
        cos_lr=True,
        label_smoothing=0.1,
        
        # å…¶ä»–
        save=True,
        plots=True,
        verbose=True,
        device='mps',
        workers=4,
        seed=42,
    )
    
    return model, results


def plot_training_curves(results_dir, save_path='training_curves.png'):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    results_dir = Path(results_dir)
    csv_path = results_dir / 'results.csv'
    
    if not csv_path.exists():
        print(f"æœªæ‰¾åˆ°: {csv_path}")
        return None
    
    df = pd.read_csv(csv_path)
    df.columns = df.columns.str.strip()
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # æŸå¤±æ›²çº¿
    ax1 = axes[0, 0]
    if 'train/loss' in df.columns:
        ax1.plot(df['epoch'], df['train/loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
    if 'val/loss' in df.columns:
        ax1.plot(df['epoch'], df['val/loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('æŸå¤±æ›²çº¿')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å‡†ç¡®ç‡æ›²çº¿
    ax2 = axes[0, 1]
    if 'metrics/accuracy_top1' in df.columns:
        ax2.plot(df['epoch'], df['metrics/accuracy_top1'], 'g-', 
                label='Top-1 å‡†ç¡®ç‡', linewidth=2)
    if 'metrics/accuracy_top5' in df.columns:
        ax2.plot(df['epoch'], df['metrics/accuracy_top5'], 'm-', 
                label='Top-5 å‡†ç¡®ç‡', linewidth=2)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.set_title('å‡†ç¡®ç‡æ›²çº¿')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([0, 1])
    
    # å­¦ä¹ ç‡æ›²çº¿
    ax3 = axes[1, 0]
    lr_cols = [col for col in df.columns if 'lr' in col.lower()]
    for col in lr_cols:
        ax3.plot(df['epoch'], df[col], label=col, linewidth=2)
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('Learning Rate')
    ax3.set_title('å­¦ä¹ ç‡æ›²çº¿')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # ç»Ÿè®¡ä¿¡æ¯
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    stats_text = "è®­ç»ƒç»Ÿè®¡\n" + "=" * 35 + "\n\n"
    stats_text += f"æ€»è®­ç»ƒè½®æ•°: {len(df)}\n\n"
    
    if 'metrics/accuracy_top1' in df.columns:
        best_acc = df['metrics/accuracy_top1'].max()
        best_epoch = df.loc[df['metrics/accuracy_top1'].idxmax(), 'epoch']
        final_acc = df['metrics/accuracy_top1'].iloc[-1]
        stats_text += f"æœ€ä½³ Top-1: {best_acc:.2%} (Epoch {int(best_epoch)})\n"
        stats_text += f"æœ€ç»ˆ Top-1: {final_acc:.2%}\n\n"
    
    if 'metrics/accuracy_top5' in df.columns:
        stats_text += f"æœ€ä½³ Top-5: {df['metrics/accuracy_top5'].max():.2%}\n"
        stats_text += f"æœ€ç»ˆ Top-5: {df['metrics/accuracy_top5'].iloc[-1]:.2%}\n\n"
    
    if 'train/loss' in df.columns:
        stats_text += f"æœ€å°è®­ç»ƒæŸå¤±: {df['train/loss'].min():.4f}\n"
    if 'val/loss' in df.columns:
        stats_text += f"æœ€å°éªŒè¯æŸå¤±: {df['val/loss'].min():.4f}\n"
    
    ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes,
            fontsize=12, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()
    
    return df


def plot_confusion_matrix(model, data_dir, class_names, save_path='confusion_matrix.png'):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    print("\næ­£åœ¨ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
    
    data_dir = Path(data_dir)
    val_dir = data_dir / 'val'
    img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    
    y_true = []
    y_pred = []
    
    for class_idx, class_name in enumerate(class_names):
        class_dir = val_dir / class_name
        if not class_dir.exists():
            continue
        
        images = [f for f in class_dir.iterdir() 
                  if f.is_file() and f.suffix.lower() in img_extensions]
        
        for img_path in tqdm(images, desc=f"é¢„æµ‹ {class_name}"):
            results = model.predict(source=str(img_path), verbose=False)
            pred_class = results[0].probs.top1
            y_true.append(class_idx)
            y_pred.append(pred_class)
    
    cm = confusion_matrix(y_true, y_pred)
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 7))
    
    # æ•°é‡æ··æ·†çŸ©é˜µ
    ax1 = axes[0]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names, ax=ax1)
    ax1.set_xlabel('é¢„æµ‹ç±»åˆ«')
    ax1.set_ylabel('çœŸå®ç±»åˆ«')
    ax1.set_title('æ··æ·†çŸ©é˜µ (æ•°é‡)')
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
    ax2 = axes[1]
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    cm_norm = np.nan_to_num(cm_norm)
    sns.heatmap(cm_norm, annot=True, fmt='.1%', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names, ax=ax2)
    ax2.set_xlabel('é¢„æµ‹ç±»åˆ«')
    ax2.set_ylabel('çœŸå®ç±»åˆ«')
    ax2.set_title('æ··æ·†çŸ©é˜µ (å½’ä¸€åŒ–)')
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()
    
    # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
    report = classification_report(y_true, y_pred, target_names=class_names)
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    print("=" * 60)
    print(report)
    
    report_path = save_path.replace('.png', '_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("åˆ†ç±»æŠ¥å‘Š\n" + "=" * 60 + "\n" + report)
    print(f"å·²ä¿å­˜: {report_path}")
    
    return cm, y_true, y_pred


def plot_per_class_accuracy(y_true, y_pred, class_names, save_path='per_class_accuracy.png'):
    """ç»˜åˆ¶æ¯ç±»å‡†ç¡®ç‡"""
    cm = confusion_matrix(y_true, y_pred)
    per_class_acc = cm.diagonal() / cm.sum(axis=1)
    per_class_acc = np.nan_to_num(per_class_acc)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    colors = plt.cm.RdYlGn(per_class_acc)
    bars = ax.barh(class_names, per_class_acc, color=colors)
    
    for bar, acc in zip(bars, per_class_acc):
        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                f'{acc:.1%}', va='center', fontsize=10)
    
    ax.set_xlabel('å‡†ç¡®ç‡')
    ax.set_title('å„ç±»åˆ«å‡†ç¡®ç‡')
    ax.set_xlim([0, 1.15])
    ax.axvline(x=np.mean(per_class_acc), color='red', linestyle='--', 
               label=f'å¹³å‡: {np.mean(per_class_acc):.1%}')
    ax.legend()
    ax.grid(True, alpha=0.3, axis='x')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def visualize_predictions(model, data_dir, class_names, num_samples=16, 
                          save_path='prediction_samples.png'):
    """å¯è§†åŒ–é¢„æµ‹æ ·æœ¬"""
    print("\næ­£åœ¨ç”Ÿæˆé¢„æµ‹å¯è§†åŒ–...")
    
    data_dir = Path(data_dir)
    val_dir = data_dir / 'val'
    img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    
    all_images = []
    for class_name in class_names:
        class_dir = val_dir / class_name
        if class_dir.exists():
            images = [f for f in class_dir.iterdir() 
                      if f.is_file() and f.suffix.lower() in img_extensions]
            for img in images:
                all_images.append((img, class_name))
    
    samples = random.sample(all_images, min(num_samples, len(all_images)))
    
    cols = 4
    rows = (len(samples) + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(16, 4 * rows))
    axes = axes.flatten()
    
    for idx, (img_path, true_label) in enumerate(samples):
        ax = axes[idx]
        
        img = cv2.imread(str(img_path))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        results = model.predict(source=str(img_path), verbose=False)
        probs = results[0].probs
        pred_idx = probs.top1
        pred_conf = probs.top1conf.item()
        pred_label = class_names[pred_idx]
        
        ax.imshow(img)
        
        is_correct = (pred_label == true_label)
        title_color = 'green' if is_correct else 'red'
        title = f"çœŸå®: {true_label}\né¢„æµ‹: {pred_label} ({pred_conf:.1%})"
        ax.set_title(title, color=title_color, fontsize=10)
        ax.axis('off')
    
    for idx in range(len(samples), len(axes)):
        axes[idx].axis('off')
    
    plt.suptitle('é¢„æµ‹ç»“æœ (ç»¿è‰²=æ­£ç¡®, çº¢è‰²=é”™è¯¯)', fontsize=14)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def visualize_wrong_predictions(model, data_dir, class_names, num_samples=12,
                                 save_path='wrong_predictions.png'):
    """å¯è§†åŒ–é”™è¯¯é¢„æµ‹"""
    print("\næ­£åœ¨æŸ¥æ‰¾é”™è¯¯é¢„æµ‹...")
    
    data_dir = Path(data_dir)
    val_dir = data_dir / 'val'
    img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    
    wrong_predictions = []
    
    for class_idx, class_name in enumerate(class_names):
        class_dir = val_dir / class_name
        if not class_dir.exists():
            continue
        
        images = [f for f in class_dir.iterdir() 
                  if f.is_file() and f.suffix.lower() in img_extensions]
        
        for img_path in images:
            results = model.predict(source=str(img_path), verbose=False)
            probs = results[0].probs
            pred_idx = probs.top1
            pred_conf = probs.top1conf.item()
            
            if pred_idx != class_idx:
                wrong_predictions.append({
                    'path': img_path,
                    'true_label': class_name,
                    'pred_label': class_names[pred_idx],
                    'confidence': pred_conf
                })
    
    if len(wrong_predictions) == 0:
        print("æ²¡æœ‰é”™è¯¯é¢„æµ‹!")
        return
    
    print(f"æ‰¾åˆ° {len(wrong_predictions)} ä¸ªé”™è¯¯é¢„æµ‹")
    
    samples = random.sample(wrong_predictions, min(num_samples, len(wrong_predictions)))
    
    cols = 4
    rows = (len(samples) + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(16, 4 * rows))
    axes = np.array(axes).flatten()
    
    for idx, sample in enumerate(samples):
        ax = axes[idx]
        
        img = cv2.imread(str(sample['path']))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        ax.imshow(img)
        title = f"çœŸå®: {sample['true_label']}\né¢„æµ‹: {sample['pred_label']} ({sample['confidence']:.1%})"
        ax.set_title(title, color='red', fontsize=10)
        ax.axis('off')
    
    for idx in range(len(samples), len(axes)):
        axes[idx].axis('off')
    
    plt.suptitle('é”™è¯¯é¢„æµ‹æ ·æœ¬åˆ†æ', fontsize=14)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def plot_top5_predictions(model, data_dir, class_names, num_samples=6,
                          save_path='top5_predictions.png'):
    """å¯è§†åŒ– Top-5 é¢„æµ‹"""
    print("\næ­£åœ¨ç”Ÿæˆ Top-5 é¢„æµ‹å¯è§†åŒ–...")
    
    data_dir = Path(data_dir)
    val_dir = data_dir / 'val'
    img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
    
    all_images = []
    for class_name in class_names:
        class_dir = val_dir / class_name
        if class_dir.exists():
            images = [f for f in class_dir.iterdir() 
                      if f.is_file() and f.suffix.lower() in img_extensions]
            for img in images:
                all_images.append((img, class_name))
    
    samples = random.sample(all_images, min(num_samples, len(all_images)))
    
    fig, axes = plt.subplots(num_samples, 2, figsize=(14, 3 * num_samples))
    
    for idx, (img_path, true_label) in enumerate(samples):
        ax_img = axes[idx, 0]
        img = cv2.imread(str(img_path))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        ax_img.imshow(img)
        ax_img.set_title(f'çœŸå®: {true_label}', fontsize=12)
        ax_img.axis('off')
        
        ax_bar = axes[idx, 1]
        results = model.predict(source=str(img_path), verbose=False)
        probs = results[0].probs
        top5_idx = probs.top5
        top5_conf = probs.top5conf.tolist()
        
        top5_names = [class_names[i] for i in top5_idx]
        colors = ['green' if name == true_label else 'steelblue' for name in top5_names]
        
        bars = ax_bar.barh(range(5), top5_conf, color=colors)
        ax_bar.set_yticks(range(5))
        ax_bar.set_yticklabels(top5_names)
        ax_bar.set_xlabel('ç½®ä¿¡åº¦')
        ax_bar.set_title('Top-5 é¢„æµ‹')
        ax_bar.set_xlim([0, 1])
        ax_bar.invert_yaxis()
        
        for bar, conf in zip(bars, top5_conf):
            ax_bar.text(conf + 0.01, bar.get_y() + bar.get_height()/2,
                       f'{conf:.1%}', va='center', fontsize=9)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def generate_summary_report(results_dir, class_names, stats, y_true=None, y_pred=None,
                            save_path='training_summary.png'):
    """ç”Ÿæˆè®­ç»ƒæ€»ç»“æŠ¥å‘Š"""
    print("\næ­£åœ¨ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
    
    results_dir = Path(results_dir)
    csv_path = results_dir / 'results.csv'
    
    fig = plt.figure(figsize=(18, 14))
    
    # 1. æ•°æ®é›†åˆ†å¸ƒ
    ax1 = fig.add_subplot(2, 3, 1)
    classes = list(stats.keys())
    counts = list(stats.values())
    colors = plt.cm.viridis(np.linspace(0, 1, len(classes)))
    bars = ax1.barh(classes, counts, color=colors)
    ax1.set_xlabel('å›¾åƒæ•°é‡')
    ax1.set_title('æ•°æ®é›†åˆ†å¸ƒ')
    ax1.bar_label(bars, padding=3)
    
    # 2. å‡†ç¡®ç‡æ›²çº¿
    ax2 = fig.add_subplot(2, 3, 2)
    if csv_path.exists():
        df = pd.read_csv(csv_path)
        df.columns = df.columns.str.strip()
        if 'metrics/accuracy_top1' in df.columns:
            ax2.plot(df['epoch'], df['metrics/accuracy_top1'], 'g-', 
                    label='Top-1', linewidth=2)
        if 'metrics/accuracy_top5' in df.columns:
            ax2.plot(df['epoch'], df['metrics/accuracy_top5'], 'b-', 
                    label='Top-5', linewidth=2)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('å‡†ç¡®ç‡æ›²çº¿')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim([0, 1])
    
    # 3. æŸå¤±æ›²çº¿
    ax3 = fig.add_subplot(2, 3, 3)
    if csv_path.exists():
        if 'train/loss' in df.columns:
            ax3.plot(df['epoch'], df['train/loss'], 'b-', label='è®­ç»ƒ', linewidth=2)
        if 'val/loss' in df.columns:
            ax3.plot(df['epoch'], df['val/loss'], 'r-', label='éªŒè¯', linewidth=2)
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Loss')
        ax3.set_title('æŸå¤±æ›²çº¿')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
    
    # 4. æ¯ç±»å‡†ç¡®ç‡
    ax4 = fig.add_subplot(2, 3, 4)
    if y_true is not None and y_pred is not None:
        cm = confusion_matrix(y_true, y_pred)
        per_class_acc = cm.diagonal() / cm.sum(axis=1)
        per_class_acc = np.nan_to_num(per_class_acc)
        colors_acc = plt.cm.RdYlGn(per_class_acc)
        bars = ax4.barh(class_names, per_class_acc, color=colors_acc)
        ax4.set_xlabel('å‡†ç¡®ç‡')
        ax4.set_title('å„ç±»åˆ«å‡†ç¡®ç‡')
        ax4.set_xlim([0, 1.1])
        for bar, acc in zip(bars, per_class_acc):
            ax4.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                    f'{acc:.0%}', va='center', fontsize=9)
    
    # 5. æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
    ax5 = fig.add_subplot(2, 3, 5)
    if y_true is not None and y_pred is not None:
        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm_norm = np.nan_to_num(cm_norm)
        sns.heatmap(cm_norm, annot=True, fmt='.0%', cmap='Blues',
                    xticklabels=class_names, yticklabels=class_names, ax=ax5,
                    annot_kws={'size': 8})
        ax5.set_title('æ··æ·†çŸ©é˜µ')
        plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=8)
        plt.setp(ax5.yaxis.get_majorticklabels(), rotation=0, fontsize=8)
    
    # 6. è®­ç»ƒæ€»ç»“æ–‡æœ¬
    ax6 = fig.add_subplot(2, 3, 6)
    ax6.axis('off')
    
    summary_text = "=" * 40 + "\n"
    summary_text += "        è®­ç»ƒæ€»ç»“æŠ¥å‘Š\n"
    summary_text += "=" * 40 + "\n\n"
    
    summary_text += f"ã€æ•°æ®é›†ã€‘\n"
    summary_text += f"  ç±»åˆ«æ•°: {len(class_names)}\n"
    summary_text += f"  æ€»å›¾åƒ: {sum(counts)}\n"
    summary_text += f"  æœ€å¤§ç±»: {max(stats, key=stats.get)} ({max(counts)})\n"
    summary_text += f"  æœ€å°ç±»: {min(stats, key=stats.get)} ({min(counts)})\n\n"
    
    if csv_path.exists():
        summary_text += f"ã€è®­ç»ƒé…ç½®ã€‘\n"
        summary_text += f"  æ€»è½®æ•°: {len(df)}\n\n"
        
        summary_text += f"ã€æœ€ç»ˆæ€§èƒ½ã€‘\n"
        if 'metrics/accuracy_top1' in df.columns:
            best_acc = df['metrics/accuracy_top1'].max()
            final_acc = df['metrics/accuracy_top1'].iloc[-1]
            best_epoch = df.loc[df['metrics/accuracy_top1'].idxmax(), 'epoch']
            summary_text += f"  æœ€ä½³ Top-1: {best_acc:.2%} (E{int(best_epoch)})\n"
            summary_text += f"  æœ€ç»ˆ Top-1: {final_acc:.2%}\n"
        
        if 'metrics/accuracy_top5' in df.columns:
            summary_text += f"  æœ€ä½³ Top-5: {df['metrics/accuracy_top5'].max():.2%}\n"
            summary_text += f"  æœ€ç»ˆ Top-5: {df['metrics/accuracy_top5'].iloc[-1]:.2%}\n"
    
    if y_true is not None and y_pred is not None:
        overall_acc = np.mean(np.array(y_true) == np.array(y_pred))
        summary_text += f"\nã€éªŒè¯é›†æ€§èƒ½ã€‘\n"
        summary_text += f"  æ•´ä½“å‡†ç¡®ç‡: {overall_acc:.2%}\n"
        summary_text += f"  å¹³å‡ç±»å‡†ç¡®ç‡: {np.mean(per_class_acc):.2%}\n"
    
    weights_dir = results_dir / 'weights'
    if weights_dir.exists():
        summary_text += f"\nã€æ¨¡å‹æ–‡ä»¶ã€‘\n"
        for f in weights_dir.glob('*.pt'):
            size_mb = f.stat().st_size / (1024 * 1024)
            summary_text += f"  {f.name}: {size_mb:.1f}MB\n"
    
    ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes,
            fontsize=10, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))
    
    plt.suptitle('å†œä¸šç—…è™«å®³ç›‘æµ‹æ¨¡å‹ - è®­ç»ƒæ€»ç»“', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"å·²ä¿å­˜: {save_path}")
    plt.show()


def evaluate_and_visualize_all(model, results_dir, data_dir, class_names, stats):
    """ç»¼åˆè¯„ä¼°å’Œå¯è§†åŒ–"""
    results_dir = Path(results_dir)
    
    print("\n" + "=" * 60)
    print("å¼€å§‹ç»¼åˆè¯„ä¼°å’Œå¯è§†åŒ–")
    print("=" * 60)
    
    vis_dir = results_dir / 'visualizations'
    vis_dir.mkdir(exist_ok=True)
    
    # 1. è®­ç»ƒæ›²çº¿
    print("\n[1/7] ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")
    plot_training_curves(results_dir, save_path=str(vis_dir / 'training_curves.png'))
    
    # 2. æ··æ·†çŸ©é˜µ
    print("\n[2/7] ç»˜åˆ¶æ··æ·†çŸ©é˜µ...")
    cm, y_true, y_pred = plot_confusion_matrix(
        model, data_dir, class_names, 
        save_path=str(vis_dir / 'confusion_matrix.png')
    )
    
    # 3. æ¯ç±»å‡†ç¡®ç‡
    print("\n[3/7] ç»˜åˆ¶æ¯ç±»å‡†ç¡®ç‡...")
    plot_per_class_accuracy(
        y_true, y_pred, class_names,
        save_path=str(vis_dir / 'per_class_accuracy.png')
    )
    
    # 4. é¢„æµ‹æ ·æœ¬
    print("\n[4/7] å¯è§†åŒ–é¢„æµ‹æ ·æœ¬...")
    visualize_predictions(
        model, data_dir, class_names, num_samples=16,
        save_path=str(vis_dir / 'prediction_samples.png')
    )
    
    # 5. é”™è¯¯é¢„æµ‹
    print("\n[5/7] å¯è§†åŒ–é”™è¯¯é¢„æµ‹...")
    visualize_wrong_predictions(
        model, data_dir, class_names, num_samples=12,
        save_path=str(vis_dir / 'wrong_predictions.png')
    )
    
    # 6. Top-5 é¢„æµ‹
    print("\n[6/7] Top-5 é¢„æµ‹å¯è§†åŒ–...")
    plot_top5_predictions(
        model, data_dir, class_names, num_samples=6,
        save_path=str(vis_dir / 'top5_predictions.png')
    )
    
    # 7. æ€»ç»“æŠ¥å‘Š
    print("\n[7/7] ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
    generate_summary_report(
        results_dir, class_names, stats, y_true, y_pred,
        save_path=str(vis_dir / 'training_summary.png')
    )
    
    print("\n" + "=" * 60)
    print(f"æ‰€æœ‰å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {vis_dir}")
    print("=" * 60)
    
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    for f in sorted(vis_dir.glob('*')):
        size_kb = f.stat().st_size / 1024
        print(f"  âœ“ {f.name} ({size_kb:.1f} KB)")
    
    return y_true, y_pred


# ============================================================
# ä¸»ç¨‹åº
# ============================================================

if __name__ == "__main__":
    
    print("\n" + "=" * 60)
    print("   å†œä¸šç—…è™«å®³ç›‘æµ‹ YOLO æ¨¡å‹è®­ç»ƒ (ä¼˜åŒ–ç‰ˆ)")
    print("=" * 60)
    
    # ==================
    # é…ç½®å‚æ•°
    # ==================
    SOURCE_DIR = "augmented"
    OUTPUT_DIR = "dataset"
    
    # ä¼˜åŒ–åçš„è®­ç»ƒå‚æ•°
    EPOCHS =50          # å¢åŠ è½®æ•°
    IMAGE_SIZE = 320      # å¢åŠ å›¾åƒå°ºå¯¸
    BATCH_SIZE = 32       # æ‰¹æ¬¡å¤§å°
    MODEL_SIZE = 's'      # ä½¿ç”¨æ›´å¤§æ¨¡å‹: n < s < m < l < x
    
    # ==================
    # æ­¥éª¤ 1: å‡†å¤‡æ•°æ®é›†
    # ==================
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 1: å‡†å¤‡æ•°æ®é›†")
    print("=" * 60)
    
    class_names, stats = prepare_classification_dataset(
        source_dir=SOURCE_DIR,
        output_dir=OUTPUT_DIR,
        train_ratio=0.8
    )
    
    # ==================
    # æ­¥éª¤ 2: å¯è§†åŒ–æ•°æ®é›†
    # ==================
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 2: å¯è§†åŒ–æ•°æ®é›†")
    print("=" * 60)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜æ•°æ®é›†å¯è§†åŒ–
    temp_vis_dir = Path('temp_visualizations')
    temp_vis_dir.mkdir(exist_ok=True)
    
    visualize_dataset(SOURCE_DIR, stats, 
                      save_path=str(temp_vis_dir / 'dataset_distribution.png'))
    show_sample_images(SOURCE_DIR, num_per_class=3, 
                       save_path=str(temp_vis_dir / 'sample_images.png'))
    
    # ==================
    # æ­¥éª¤ 3: è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨ä¼˜åŒ–å‚æ•°ï¼‰
    # ==================
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 3: è®­ç»ƒæ¨¡å‹ (ä¼˜åŒ–ç‰ˆ)")
    print("=" * 60)
    
    model, results = train_model_optimized(
        data_dir=OUTPUT_DIR,
        epochs=EPOCHS,
        imgsz=IMAGE_SIZE,
        batch=BATCH_SIZE,
        model_size=MODEL_SIZE
    )
    
    # ==================
    # æ­¥éª¤ 4: è·å–ç»“æœç›®å½•
    # ==================
    results_dir = Path('runs/classify/pest_disease_optimized')
    if not results_dir.exists():
        classify_dir = Path('runs/classify')
        results_dirs = sorted(classify_dir.glob('pest_disease*'))
        if results_dirs:
            results_dir = results_dirs[-1]
    
    print(f"\nç»“æœç›®å½•: {results_dir}")
    
    # ==================
    # æ­¥éª¤ 5: ç»¼åˆè¯„ä¼°å’Œå¯è§†åŒ–
    # ==================
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 4: ç»¼åˆè¯„ä¼°å’Œå¯è§†åŒ–")
    print("=" * 60)
    
    y_true, y_pred = evaluate_and_visualize_all(
        model=model,
        results_dir=results_dir,
        data_dir=OUTPUT_DIR,
        class_names=class_names,
        stats=stats
    )
    
    # ==================
    # æ­¥éª¤ 6: å¤åˆ¶æ•°æ®é›†å¯è§†åŒ–åˆ°ç»“æœç›®å½•
    # ==================
    vis_dir = results_dir / 'visualizations'
    for f in temp_vis_dir.glob('*.png'):
        shutil.copy2(f, vis_dir / f.name)
        print(f"  å·²å¤åˆ¶: {f.name}")
    
    # æ¸…ç†ä¸´æ—¶ç›®å½•
    shutil.rmtree(temp_vis_dir)
    
    # ==================
    # æ­¥éª¤ 7: æ‰“å°æœ€ç»ˆä¿¡æ¯
    # ==================
    print("\n" + "=" * 60)
    print("è®­ç»ƒå®Œæˆ!")
    print("=" * 60)
    
    print(f"\nğŸ“ ç»“æœä¿å­˜ä½ç½®: {results_dir}")
    print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {vis_dir}")
    
    weights_dir = results_dir / 'weights'
    print(f"\nğŸ”§ æ¨¡å‹æ–‡ä»¶:")
    print(f"   - {weights_dir / 'best.pt'} (æœ€ä½³æ¨¡å‹)")
    print(f"   - {weights_dir / 'last.pt'} (æœ€åæ¨¡å‹)")
    
    print("\nğŸ“ˆ æ‰€æœ‰ç”Ÿæˆçš„å¯è§†åŒ–:")
    for f in sorted(vis_dir.glob('*')):
        print(f"   âœ“ {f.name}")
    
    print("\n" + "=" * 60)

